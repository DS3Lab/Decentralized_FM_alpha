#!/bin/bash
#BSUB -n 2                     # 1 cores
#BSUB -W 3:59                   # 3-minutes run-time
#BSUB -R "rusage[mem=8000]"     # 32 GB per core
#BSUB -R "rusage[ngpus_excl_p=1]"
#BSUB -R "select[gpu_mtotal0>=10000]"
#BSUB -o /cluster/home/juewang/fm/t5_exe_log/t5.out.%J
#BSUB -e /cluster/home/juewang/fm/t5_exe_log/t5.err.%J

module load gcc/6.3.0 cuda/11.0.3             # Load modules from Euler setup
source activate pipeline                          # Activate my conda python environment
cd /cluster/home/juewang/workspace/GPT-home-private     # Change directory

nvidia-smi

world_size=16

DIST_CONF="--pp-mode pipe_async_sample_enc_dec_mask --pipeline-group-size $world_size --cuda-id 0"
MODEL_CONF="--model-type t5 --model-name /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/pretrained_models/ul2-new --num-iters 99999999999"
INFERENCE_CONF="--budget 20800 --num-layers 2"
COOR_CONF="--coordinator-server-ip 129.132.93.105"
#!/bin/bash

export NCCL_SOCKET_IFNAME=access
export GLOO_SOCKET_IFNAME=access
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1

python -u dist_inference_runner_w_euler_coordinator.py $DIST_CONF $MODEL_CONF $INFERENCE_CONF $COOR_CONF \

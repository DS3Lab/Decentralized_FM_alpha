#!/bin/bash
#BSUB -n 64                     # 1 cores
#BSUB -W 3:59                   # 3-minutes run-time
#BSUB -R "rusage[mem=8000]"     # 8 GB per core
#BSUB -o /cluster/home/biyuan/exe_log/hybrid_cpu_opt175.out.%J
#BSUB -e /cluster/home/biyuan/exe_log/hybrid_cpu_opt175.err.%J

module load gcc/6.3.0 cuda/11.0.3             # Load modules from Euler setup
source activate base                          # Activate my conda python environment
cd /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/GPT-home-private       # Change directory

nvidia-smi

world_size=46
pipeline_size=16
stage_num_layers=6
global_num_layers=$(($stage_num_layers*$pipeline_size))


DIST_CONF="--world-size $world_size --pipeline-group-size $pipeline_size --node-type CPU --use-cuda False"
MODEL_CONF="--model-type gptj --model-name ./pretrained_models/gpt-j-175B"
INFERENCE_CONF="--num-iters 20 --input-seq-length 512 --generate-seq-length 32 --prompt-micro-batch-size 1 --token-micro-batch-size 1 --stage-num-layers $stage_num_layers --global-num-layers $global_num_layers"
BUF_CONF="--producer-buffer-size 30 --consumer-buffer-size 1"

COOR_CONF="--coordinator-server-ip 129.132.93.84"

export NCCL_SOCKET_IFNAME=access
export GLOO_SOCKET_IFNAME=access

##python dist_training_runner_w_coordinator.py $DIST_CONF $MODEL_CONF $COOR_CONF
python dist_training_runner_w_coordinator.py $DIST_CONF $MODEL_CONF $COOR_CONF $INFERENCE_CONF $BUF_CONF \
